{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "- Create classes to represent Data, Metadata, and Dataset? (dataset being the combination of the two, with fns which link them; ie. for cross-checking the type defined in meta is what the data type actually is)\n",
    "- For Meta, can be read in different formats, and then exported in different formats\n",
    "  - For dataset, meta must be a particular format\n",
    "\n",
    "- Filter out rows with all nulls\n",
    "- Create unique_values function: input basename & output dataframe with unique values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Initial import and formatting of SPSS data.\n",
    "output-file: read.html\n",
    "title: read\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import pyspssio\n",
    "from pathlib import Path\n",
    "from typing import Optional, Any\n",
    "from fastcore.utils import *\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic.dataclasses import dataclass\n",
    "# from pandera import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/raw\")\n",
    "df, meta = pyspssio.read_sav(data_dir/\"G214_PQ.sav\")\n",
    "df = pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@dataclass\n",
    "class Metadata:\n",
    "    label: str\n",
    "    field_values: dict[int, str]\n",
    "    field_type: str\n",
    "    field_width: int\n",
    "    decimals: int\n",
    "    variable_type: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(label='Ever had back pain', field_values={-99: 'Missing', 0: 'No', 1: 'Yes'}, field_type='Numeric', field_width=3, decimals=0, variable_type='Nominal')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metadata(\n",
    "    label = \"Ever had back pain\",\n",
    "    field_values = {-99: \"Missing\", 0: \"No\", 1: \"Yes\"},\n",
    "    field_type = \"Numeric\",\n",
    "    field_width = 3,\n",
    "    decimals =  0,\n",
    "    variable_type = \"Nominal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def unpack_variable_types(input_dict):\n",
    "    \"...\"\n",
    "    field_type = {}\n",
    "    decimals = {}\n",
    "    \n",
    "    for key, value in input_dict.items():\n",
    "        if value.startswith('F'):\n",
    "            field_type[key] = 'Numeric'\n",
    "            dec = value.split('.')[1]\n",
    "            decimals[key] = dec if dec != '0' else '0'\n",
    "        elif value.startswith('DATE'):\n",
    "            field_type[key] = 'Date'\n",
    "            decimals[key] = '0'\n",
    "        elif value.startswith('A'):\n",
    "            field_type[key] = 'String'\n",
    "            decimals[key] = '0'\n",
    "    \n",
    "    return field_type, decimals\n",
    "\n",
    "def reformat_metadata(m: pyreadstat.metadata_container, # metadata from pyreadstat\n",
    "                     ) -> dict[dict[str, Any]]:\n",
    "    \"Reformat metadata into a more readable and consistent format\"\n",
    "    field_type, decimals = unpack_variable_types(m.original_variable_types)\n",
    "    metadata = {\n",
    "        \"Label\": m.column_names_to_labels,\n",
    "        \"Field Type\": field_type,\n",
    "        \"Field Width\": m.variable_display_width,\n",
    "        \"Decimals\": decimals,\n",
    "        \"Variable Type\": m.variable_measure,\n",
    "        \"Field Values\": m.variable_value_labels\n",
    "    }\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add Data and Metadata classes, and nest them in the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_pyreadstat(data_dir: str|Path, \n",
    "                    file: str, \n",
    "                    cols: Optional[list[str]] = None\n",
    "                    ) -> pl.LazyFrame:\n",
    "    df, meta = pyreadstat.read_sav(f\"{data_dir}/{file}\", usecols=cols)\n",
    "    df = pl.from_pandas(df).lazy()\n",
    "    return df, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    file: str\n",
    "    data_dir: str | Path\n",
    "    prefix: Optional[str] = None\n",
    "    variables: Optional[list[str]] = None\n",
    "\n",
    "    def load_data(self) -> tuple[pl.LazyFrame, dict[dict[str, Any]]]:\n",
    "        \"Output data and metadata.\"\n",
    "        df, meta = read_pyreadstat(self.data_dir, self.file, self.variables)\n",
    "        meta = reformat_metadata(meta)\n",
    "        return df, meta\n",
    "    \n",
    "        # def strip_prefix(self, df: pl.LazyFrame) -> pl.DataFrame:\n",
    "    #     stripped_columns = {col: col.replace(self.prefix, \"\") for col in self.variables}\n",
    "    #     df = df.rename(stripped_columns)\n",
    "    #     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, meta = Dataset(\"G214_PQ.sav\", data_dir).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    Dataset(\"G214_PQ.sav\", data_dir, \"G214_PQ_\", [\"ID\", \"G214_PQ_PN17\", \"G214_PQ_PN25\", \"G214_PQ_PN34\", \"G214_PQ_PN35\", \"G214_PQ_PN36\"]),\n",
    "    Dataset(\"G214_SQ.sav\", data_dir, \"G214_SQ_\", [\"ID\", \"G214_SQ_PN17\", \"G214_SQ_PN25\", \"G214_SQ_PN34\", \"G214_SQ_PN35\", \"G214_SQ_PN36\"]),\n",
    "    Dataset(\"G217_PQ.sav\", data_dir, \"G217_PQ_\", [\"ID\", \"G217_PQ_PN17\", \"G217_PQ_PN25\", \"G217_PQ_PN34\", \"G217_PQ_PN35\", \"G217_PQ_PN36\", \"G217_PQ_PN38\", \"G217_PQ_PN9\"]),\n",
    "    Dataset(\"G217_SQ.sav\", data_dir, \"G217_SQ_\", [\"ID\", \"G217_SQ_PN17\", \"G217_SQ_PN25\", \"G217_SQ_PN34\", \"G217_SQ_PN35\", \"G217_SQ_PN36\", \"G217_SQ_PN38\", \"G217_SQ_PN9\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_and_filter_data(datasets: list[Dataset]\n",
    "                         ) -> list[pl.LazyFrame]:\n",
    "    \"\"\"\n",
    "    Take a list of `Dataset`s and return a list of the respective dataframes \n",
    "    and metadata for each dataset, filtered for the given columns.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    metadata = []\n",
    "    for ds in datasets:\n",
    "        df, meta = ds.load_data()\n",
    "        dataframes.append(df)\n",
    "        metadata.append(meta)\n",
    "    return dataframes, metadata\n",
    "\n",
    "def combine_dataframes(dataframes: list[pl.LazyFrame]\n",
    "                       ) -> pl.LazyFrame:\n",
    "    \"Take a list of dataframes and return a single, combined dataframe.\"\n",
    "    combined_df = dataframes[0]\n",
    "    for df in dataframes[1:]:\n",
    "        combined_df = combined_df.join(df, on=\"ID\", how=\"full\", coalesce=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes, metadata = read_and_filter_data(datasets)\n",
    "df = combine_dataframes(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_dictionaries(dicts: list[dict[str, Any]]\n",
    "                       ) -> dict[str, Any]:\n",
    "    \"Merge a series of nested dictionaries.\"\n",
    "    merged_dict = defaultdict(dict)\n",
    "    for d in dicts:\n",
    "        for key, nested_dict in d.items():\n",
    "            for nested_key, value in nested_dict.items():\n",
    "                if nested_key not in merged_dict[key]:\n",
    "                    merged_dict[key][nested_key] = value\n",
    "                elif isinstance(value, dict):\n",
    "                    merged_dict[key][nested_key].update(value)\n",
    "    return dict(merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_merged = merge_dictionaries(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G214_PQ_PN17</th>\n",
       "      <th>G214_SQ_PN17</th>\n",
       "      <th>G217_PQ_PN17</th>\n",
       "      <th>G217_SQ_PN17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>Ever had back pain</td>\n",
       "      <td>Ever had back pain</td>\n",
       "      <td>Ever had back pain</td>\n",
       "      <td>Ever had back pain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field Type</th>\n",
       "      <td>Numeric</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field Width</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decimals</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable Type</th>\n",
       "      <td>scale</td>\n",
       "      <td>scale</td>\n",
       "      <td>scale</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field Values</th>\n",
       "      <td>{0.0: 'No', 1.0: 'Yes', 8.0: 'Not applicable',...</td>\n",
       "      <td>{0.0: 'No', 1.0: 'Yes', 8.0: 'Not applicable',...</td>\n",
       "      <td>{0.0: 'No', 1.0: 'Yes', 7.0: 'Involved in inco...</td>\n",
       "      <td>{0.0: 'No', 1.0: 'Yes', 9.0: 'Not stated'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    G214_PQ_PN17  \\\n",
       "Label                                         Ever had back pain   \n",
       "Field Type                                               Numeric   \n",
       "Field Width                                                    8   \n",
       "Decimals                                                       0   \n",
       "Variable Type                                              scale   \n",
       "Field Values   {0.0: 'No', 1.0: 'Yes', 8.0: 'Not applicable',...   \n",
       "\n",
       "                                                    G214_SQ_PN17  \\\n",
       "Label                                         Ever had back pain   \n",
       "Field Type                                               Numeric   \n",
       "Field Width                                                    8   \n",
       "Decimals                                                       0   \n",
       "Variable Type                                              scale   \n",
       "Field Values   {0.0: 'No', 1.0: 'Yes', 8.0: 'Not applicable',...   \n",
       "\n",
       "                                                    G217_PQ_PN17  \\\n",
       "Label                                         Ever had back pain   \n",
       "Field Type                                               Numeric   \n",
       "Field Width                                                    8   \n",
       "Decimals                                                       0   \n",
       "Variable Type                                              scale   \n",
       "Field Values   {0.0: 'No', 1.0: 'Yes', 7.0: 'Involved in inco...   \n",
       "\n",
       "                                             G217_SQ_PN17  \n",
       "Label                                 Ever had back pain?  \n",
       "Field Type                                        Numeric  \n",
       "Field Width                                             8  \n",
       "Decimals                                                0  \n",
       "Variable Type                                       scale  \n",
       "Field Values   {0.0: 'No', 1.0: 'Yes', 9.0: 'Not stated'}  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(meta_merged).T.filter(regex=\"PN17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
